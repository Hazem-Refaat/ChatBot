{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"Kaludi/Customer-Support-Responses\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:16:18.431692Z","iopub.execute_input":"2023-09-12T11:16:18.431969Z","iopub.status.idle":"2023-09-12T11:16:21.160388Z","shell.execute_reply.started":"2023-09-12T11:16:18.431943Z","shell.execute_reply":"2023-09-12T11:16:21.159208Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/Kaludi--Customer-Support-Responses to /root/.cache/huggingface/datasets/csv/Kaludi--Customer-Support-Responses-c8ff6fbc71b60d61/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87f10496978494a8f614fb16ed774d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/12.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fbb230035c94702afe8dbd228434088"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49da99cb7f82491c91b2db7036459701"}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/Kaludi--Customer-Support-Responses-c8ff6fbc71b60d61/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cede6494ef7a4c159183a90e9f895e2b"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-11T12:08:52.563861Z","iopub.execute_input":"2023-09-11T12:08:52.564534Z","iopub.status.idle":"2023-09-11T12:08:52.572386Z","shell.execute_reply.started":"2023-09-11T12:08:52.564497Z","shell.execute_reply":"2023-09-11T12:08:52.571140Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['query', 'response'],\n        num_rows: 74\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Concatenate all utterances within a dialogue and map to 'dialog' key\ndef concatenate_utterances(example):\n    example['dialog'] =  \"<USER>\" + example['query'] + \"<ASSISTANT>\" + example['response']\n    return example\n\n# Apply the function to all examples in the dataset\ndataset = dataset.map(concatenate_utterances)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:16:29.512921Z","iopub.execute_input":"2023-09-12T11:16:29.513396Z","iopub.status.idle":"2023-09-12T11:16:29.604860Z","shell.execute_reply.started":"2023-09-12T11:16:29.513357Z","shell.execute_reply":"2023-09-12T11:16:29.603988Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/74 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82dac14ec36e40178c794d121194460d"}},"metadata":{}}]},{"cell_type":"code","source":"#dataset['train']['dialog']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer , AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n\n# Set the padding token to the end-of-sequence token\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-medium')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:17:06.612395Z","iopub.execute_input":"2023-09-12T11:17:06.612847Z","iopub.status.idle":"2023-09-12T11:17:41.568512Z","shell.execute_reply.started":"2023-09-12T11:17:06.612810Z","shell.execute_reply":"2023-09-12T11:17:41.567490Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4497240db7cb41649392e7103466fd08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"814912bcaf834587ab9c061435874167"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45181cc3aeb74e718a7c9dafc628fcb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24146498690446e5ade5118daa1b908f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16d4dc9cfc8b473ab41199a11d337e47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8525567ef38642b18251fddfcada1283"}},"metadata":{}}]},{"cell_type":"code","source":"encoded = tokenizer(dataset['train']['dialog'], truncation=True, padding='max_length', max_length=168, return_tensors = 'pt')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:17:57.241133Z","iopub.execute_input":"2023-09-12T11:17:57.241575Z","iopub.status.idle":"2023-09-12T11:17:57.279349Z","shell.execute_reply.started":"2023-09-12T11:17:57.241536Z","shell.execute_reply":"2023-09-12T11:17:57.278325Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"input_ids = encoded['input_ids']\n\nattention_mask = encoded['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:17:59.841174Z","iopub.execute_input":"2023-09-12T11:17:59.841708Z","iopub.status.idle":"2023-09-12T11:17:59.850270Z","shell.execute_reply.started":"2023-09-12T11:17:59.841668Z","shell.execute_reply":"2023-09-12T11:17:59.849383Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset\n\ntrain_dataset =TensorDataset(input_ids, attention_mask)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:18:01.827175Z","iopub.execute_input":"2023-09-12T11:18:01.827567Z","iopub.status.idle":"2023-09-12T11:18:01.832678Z","shell.execute_reply.started":"2023-09-12T11:18:01.827534Z","shell.execute_reply":"2023-09-12T11:18:01.831456Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 16\n\ntrain_loader = DataLoader(train_dataset, batch_size = batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:18:03.518474Z","iopub.execute_input":"2023-09-12T11:18:03.518939Z","iopub.status.idle":"2023-09-12T11:18:03.525585Z","shell.execute_reply.started":"2023-09-12T11:18:03.518902Z","shell.execute_reply":"2023-09-12T11:18:03.524261Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\ndevice_ids = [0, 1]  # IDs of the GPUs you want to use\nmodel = model.to('cuda')\nmodel = nn.DataParallel(model, device_ids=device_ids)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:18:06.149414Z","iopub.execute_input":"2023-09-12T11:18:06.149894Z","iopub.status.idle":"2023-09-12T11:18:14.242199Z","shell.execute_reply.started":"2023-09-12T11:18:06.149842Z","shell.execute_reply":"2023-09-12T11:18:14.241170Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:18:20.238896Z","iopub.execute_input":"2023-09-12T11:18:20.239966Z","iopub.status.idle":"2023-09-12T11:18:20.247486Z","shell.execute_reply.started":"2023-09-12T11:18:20.239927Z","shell.execute_reply":"2023-09-12T11:18:20.246266Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"num_epochs = 50\n\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n    model.train()\n    for input_ids ,attention_mask  in train_loader:\n        optimizer.zero_grad()\n        input_ids = input_ids.to('cuda')\n        attention_mask = attention_mask.to('cuda')\n        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n        loss = outputs.loss\n        loss.sum().backward()\n        optimizer.step()\n        \n\n        total_loss += loss.sum().item()\n\n    average_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch + 1}/{num_epochs} - Average Loss: {average_loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:18:22.496291Z","iopub.execute_input":"2023-09-12T11:18:22.496657Z","iopub.status.idle":"2023-09-12T11:24:04.847553Z","shell.execute_reply.started":"2023-09-12T11:18:22.496628Z","shell.execute_reply":"2023-09-12T11:24:04.846406Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50 - Average Loss: 5.847833490371704\nEpoch 2/50 - Average Loss: 2.9871429443359374\nEpoch 3/50 - Average Loss: 2.6249560832977297\nEpoch 4/50 - Average Loss: 2.2473045349121095\nEpoch 5/50 - Average Loss: 1.9546013116836547\nEpoch 6/50 - Average Loss: 1.6581624507904054\nEpoch 7/50 - Average Loss: 1.3974198341369628\nEpoch 8/50 - Average Loss: 1.213204550743103\nEpoch 9/50 - Average Loss: 1.049602174758911\nEpoch 10/50 - Average Loss: 0.9454992055892945\nEpoch 11/50 - Average Loss: 0.8614281058311463\nEpoch 12/50 - Average Loss: 0.8025826811790466\nEpoch 13/50 - Average Loss: 0.7631384849548339\nEpoch 14/50 - Average Loss: 0.7297192811965942\nEpoch 15/50 - Average Loss: 0.7031514525413514\nEpoch 16/50 - Average Loss: 0.6684106111526489\nEpoch 17/50 - Average Loss: 0.6336804389953613\nEpoch 18/50 - Average Loss: 0.6044877886772155\nEpoch 19/50 - Average Loss: 0.5955815076828003\nEpoch 20/50 - Average Loss: 0.5672674179077148\nEpoch 21/50 - Average Loss: 0.5451953172683716\nEpoch 22/50 - Average Loss: 0.5246188640594482\nEpoch 23/50 - Average Loss: 0.5114919781684876\nEpoch 24/50 - Average Loss: 0.4862884283065796\nEpoch 25/50 - Average Loss: 0.47411918044090273\nEpoch 26/50 - Average Loss: 0.4589333713054657\nEpoch 27/50 - Average Loss: 0.4431314945220947\nEpoch 28/50 - Average Loss: 0.4367156982421875\nEpoch 29/50 - Average Loss: 0.4190434694290161\nEpoch 30/50 - Average Loss: 0.40455225110054016\nEpoch 31/50 - Average Loss: 0.39098061323165895\nEpoch 32/50 - Average Loss: 0.3753260254859924\nEpoch 33/50 - Average Loss: 0.36474761962890623\nEpoch 34/50 - Average Loss: 0.3561270236968994\nEpoch 35/50 - Average Loss: 0.3504886269569397\nEpoch 36/50 - Average Loss: 0.3379708230495453\nEpoch 37/50 - Average Loss: 0.3366907060146332\nEpoch 38/50 - Average Loss: 0.3240083158016205\nEpoch 39/50 - Average Loss: 0.3256950378417969\nEpoch 40/50 - Average Loss: 0.3083390831947327\nEpoch 41/50 - Average Loss: 0.2976917564868927\nEpoch 42/50 - Average Loss: 0.3035662412643433\nEpoch 43/50 - Average Loss: 0.29823734760284426\nEpoch 44/50 - Average Loss: 0.2870411992073059\nEpoch 45/50 - Average Loss: 0.2850975453853607\nEpoch 46/50 - Average Loss: 0.27674598097801206\nEpoch 47/50 - Average Loss: 0.27510420978069305\nEpoch 48/50 - Average Loss: 0.2639430582523346\nEpoch 49/50 - Average Loss: 0.2657341003417969\nEpoch 50/50 - Average Loss: 0.2660043120384216\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model\nmodel.module.save_pretrained(\"Model\")\n# Save the tokenizer\ntokenizer.save_pretrained('Tokenizer')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:24:11.588832Z","iopub.execute_input":"2023-09-12T11:24:11.589209Z","iopub.status.idle":"2023-09-12T11:24:14.420408Z","shell.execute_reply.started":"2023-09-12T11:24:11.589177Z","shell.execute_reply":"2023-09-12T11:24:14.419174Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"('Tokenizer/tokenizer_config.json',\n 'Tokenizer/special_tokens_map.json',\n 'Tokenizer/vocab.json',\n 'Tokenizer/merges.txt',\n 'Tokenizer/added_tokens.json',\n 'Tokenizer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained('/kaggle/working/Model')\n\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/working/Tokenizer')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:24:33.774738Z","iopub.execute_input":"2023-09-12T11:24:33.775335Z","iopub.status.idle":"2023-09-12T11:24:39.404709Z","shell.execute_reply.started":"2023-09-12T11:24:33.775294Z","shell.execute_reply":"2023-09-12T11:24:39.403490Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"while True:\n    user_input =  input(\"You: \")\n    if user_input.lower() == 'exit':\n            break\n    user_input = \"<USER>\" + user_input + \"<ASSISTANT>\"\n    temperature = 0.7  \n    max_response_length = 168  # Max bot response\n\n    input_ids = tokenizer.encode(user_input, truncation=True, return_tensors='pt')\n    with torch.no_grad():\n        response = model.generate(input_ids, pad_token_id=tokenizer.eos_token_id, max_length=max_response_length, temperature=temperature)\n    bot_response = tokenizer.decode(response[0], skip_special_tokens=True)\n    # Remove user input from bot response\n    bot_response = bot_response[len(user_input):].strip()\n    print(\"Bot: \" + bot_response)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:36:51.359619Z","iopub.execute_input":"2023-09-12T11:36:51.359977Z","iopub.status.idle":"2023-09-12T11:37:27.974969Z","shell.execute_reply.started":"2023-09-12T11:36:51.359947Z","shell.execute_reply":"2023-09-12T11:37:27.973828Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdin","text":"You:  problem\n"},{"name":"stdout","text":"Bot: We apologize for the inconvenience. Can you please provide a description of the issue you're experiencing and your email address so we can follow up with you?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  i am facing an issue\n"},{"name":"stdout","text":"Bot: We apologize for the inconvenience. Can you please provide a description of the issue you're experiencing and your email address so we can follow up with you?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  exit\n"}]}]}